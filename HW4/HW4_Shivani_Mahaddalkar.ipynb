{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 4: MNB and SVM for Causal Language Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries and the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as p\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "train=p.read_csv(\"pubmed_causal_language_use.csv\")\n",
    "y=train['label'].values\n",
    "X=train['sentence'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validating using 5 runs for different vectorizers and picking the vectroizer with the highest average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6504446150401433\n",
      "0.6618793248675218\n",
      "0.6736392327458443\n"
     ]
    }
   ],
   "source": [
    "##MNB TFIDF\n",
    "mNB_tfidf_pipe = Pipeline([('nb_tf',TfidfVectorizer(encoding='latin-1',use_idf=True,binary=False, stop_words='english')),('nb',MultinomialNB())])\n",
    "scores = cross_val_score(mNB_tfidf_pipe,X,y,cv=5)\n",
    "print(sum(scores)/len(scores))\n",
    "\n",
    "##MNB TF\n",
    "mNB_tf_pipe = Pipeline([('nb_tf',TfidfVectorizer(encoding='latin-1',use_idf=False,binary=False, stop_words='english')),('nb',MultinomialNB())])\n",
    "scores = cross_val_score(mNB_tf_pipe,X,y,cv=5)\n",
    "print(sum(scores)/len(scores))\n",
    "\n",
    "##MNB with Bool\n",
    "nb_clf_pipe = Pipeline([('vect', CountVectorizer(encoding='latin-1',ngram_range =(1,2), binary=True, stop_words='english')),('nb', MultinomialNB())])\n",
    "scores = cross_val_score(nb_clf_pipe, X, y, cv=5)\n",
    "avg=sum(scores)/len(scores)\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into train and test for class prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the data using the count boolean vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1225, 5318)\n"
     ]
    }
   ],
   "source": [
    "ngram_count_vectorizer = CountVectorizer(encoding='latin-1', binary=True, stop_words='english')\n",
    "X_train_vec1 = ngram_count_vectorizer.fit_transform(X_train)\n",
    "X_test_vec1 = ngram_count_vectorizer.transform(X_test)\n",
    "print(X_test_vec1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "(4, 5318)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# initialize the MNB model\n",
    "nb_clf= MultinomialNB()\n",
    "\n",
    "# use the training data to train the MNB model\n",
    "# feature_log_prob_ stores the conditional probs for all categories\n",
    "# if the labels are strings, the index is in alphabetic order\n",
    "# e.g. 'f' comes before 't' in alphabet, so 'f' is in [0] dimension and 't' in [1]\n",
    "\n",
    "nb_clf.fit(X_train_vec1,y_train)\n",
    "print(nb_clf.classes_)\n",
    "print(nb_clf.feature_log_prob_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 features for all the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-5.6636113099669245, 'treatment'), (-5.6636113099669245, 'trial'), (-5.642992022764188, 'findings'), (-5.642992022764188, 'high'), (-5.474369310328396, 'needed'), (-5.423938456701504, 'clinical'), (-5.2721324438335, 'risk'), (-5.165364468407794, 'study'), (-5.092161064384499, 'studies'), (-4.636972520923904, 'patients')]\n"
     ]
    }
   ],
   "source": [
    "feature_ranks0 = sorted(zip(nb_clf.feature_log_prob_[0], ngram_count_vectorizer.get_feature_names()))\n",
    "no_relationship_features = feature_ranks0[-10:]\n",
    "print(no_relationship_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-6.031122227714141, 'did'), (-6.031122227714141, 'effect'), (-6.031122227714141, 'improved'), (-5.986670465143307, 'cancer'), (-5.9441108507245115, 'effective'), (-5.789960170897253, 'study'), (-5.789960170897253, 'treatment'), (-5.754868851085982, 'weight'), (-5.625657119605977, 'risk'), (-5.027820118850356, 'patients')]\n"
     ]
    }
   ],
   "source": [
    "feature_ranks1 = sorted(zip(nb_clf.feature_log_prob_[1], ngram_count_vectorizer.get_feature_names()))\n",
    "direct_causal_features = feature_ranks1[-10:]\n",
    "print(direct_causal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-6.5466419284444735, 'suggest'), (-6.451331748640149, 'disease'), (-6.451331748640149, 'reduce'), (-6.451331748640149, 'results'), (-6.3643203716505194, 'cancer'), (-6.3643203716505194, 'role'), (-6.284277663976983, 'increase'), (-6.2101696918232605, 'improve'), (-5.55339015543419, 'patients'), (-5.383491118638792, 'risk')]\n"
     ]
    }
   ],
   "source": [
    "feature_ranks2 = sorted(zip(nb_clf.feature_log_prob_[2], ngram_count_vectorizer.get_feature_names()))\n",
    "conditional_causal_features = feature_ranks2[-10:]\n",
    "print(conditional_causal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-5.5838961648388485, 'cancer'), (-5.5838961648388485, 'diabetes'), (-5.54222346843828, 'women'), (-5.502218133824581, 'higher'), (-5.373600756002488, 'levels'), (-5.373600756002488, 'study'), (-5.290909040157374, 'increased'), (-4.63002272181565, 'patients'), (-4.436831492784792, 'risk'), (-4.263559771510756, 'associated')]\n"
     ]
    }
   ],
   "source": [
    "feature_ranks3 = sorted(zip(nb_clf.feature_log_prob_[3], ngram_count_vectorizer.get_feature_names()))\n",
    "correlational_features = feature_ranks3[-10:]\n",
    "print(correlational_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[451  32   2  87]\n",
      " [ 53  71   0  65]\n",
      " [ 31  21   3  21]\n",
      " [ 37  10   0 341]]\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix (row: ground truth; col: prediction)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = nb_clf.fit(X_train_vec1, y_train).predict(X_test_vec1)\n",
    "cm=confusion_matrix(y_test, y_pred, labels=[0,1,2,3])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78846154 0.52985075 0.6        0.66342412]\n",
      "[0.78846154 0.37566138 0.03947368 0.87886598]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79       572\n",
      "           1       0.53      0.38      0.44       189\n",
      "           2       0.60      0.04      0.07        76\n",
      "           3       0.66      0.88      0.76       388\n",
      "\n",
      "    accuracy                           0.71      1225\n",
      "   macro avg       0.65      0.52      0.51      1225\n",
      "weighted avg       0.70      0.71      0.68      1225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "print(precision_score(y_test, y_pred, average=None))\n",
    "print(recall_score(y_test, y_pred, average=None))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['0','1','2','3']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The worst QOL domain related to environmental stimuli and the best QOL domain to limitations of the activities.\n",
      "Incident PD patients treated with low GDP solution have less severe systemic inflammation but trends of less ultrafiltration, and more fluid accumulation.\n",
      "Weight loss, satiety and adverse symptoms demonstrated only slight changes between 3 and 8\\\\xa0years post-operatively.\n",
      "Epidemiological trends are more or less common to those of developing countries with a predominance of invasive ductal carcinoma.\n",
      "Reductions in LDL-C were greater among women randomized to both calcium+vitamin D and hormone therapy than for those randomized to either intervention alone or to placebo.\n",
      "Compared to a cognitive-behavioral program, after the intervention, adolescents who received mindfulness showed greater reductions in depressive symptoms and better insulin resistance.\n",
      "Team leader and team member are under moderate workloads during a pediatric sepsis scenario with team leader under high workloads (> 60) in the mental demand and effort subscales.\n",
      "Overall hypoglycemia rates were similar except for an increase in 0-2-h postmeal hypoglycemia with faster aspart.\n",
      "The results in this trial did not highlight any differences between  those who received the intervention and those who received usual care.\n",
      "During the same time period, the weight gain of very preterm infants improved, significantly.\n",
      "errors: 10\n"
     ]
    }
   ],
   "source": [
    "err_cnt = 0\n",
    "for i in range(0, len(y_test)):\n",
    "    if(y_test[i]==3 and y_pred[i]==1):\n",
    "        print(X_test[i])\n",
    "        err_cnt = err_cnt+1\n",
    "print(\"errors:\", err_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "However, most had playground equipment, courts, and outdoor play areas.\n",
      "The potential disease-modifying effects of simvastatin on CSF phospho-tau should be further investigated in persons with hypercholesterolemia.\n",
      "errors: 2\n"
     ]
    }
   ],
   "source": [
    "err_cnt = 0\n",
    "for i in range(0, len(y_test)):\n",
    "    if(y_test[i]==0 and y_pred[i]==2):\n",
    "        print(X_test[i])\n",
    "        err_cnt = err_cnt+1\n",
    "print(\"errors:\", err_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validating using 5 runs for different vectorizers and picking the vectroizer with the highest average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6948767979187325\n",
      "0.7066393713548498\n",
      "0.7082738913945132\n"
     ]
    }
   ],
   "source": [
    "##SVC TFIDF\n",
    "svc_tfidf_pipe = Pipeline([('nb_tf',TfidfVectorizer(encoding='latin-1',use_idf=True,binary=False, stop_words='english')),('svc',LinearSVC())])\n",
    "scores = cross_val_score(svc_tfidf_pipe,X,y,cv=5)\n",
    "print(sum(scores)/len(scores))\n",
    "\n",
    "##SVC TF\n",
    "svc_tf_pipe = Pipeline([('nb_tf',TfidfVectorizer(encoding='latin-1',use_idf=False,binary=False, stop_words='english')),('svc',LinearSVC())])\n",
    "scores = cross_val_score(svc_tf_pipe,X,y,cv=5)\n",
    "print(sum(scores)/len(scores))\n",
    "\n",
    "##SVC with Bool\n",
    "svc_clf_pipe = Pipeline([('vect', CountVectorizer(encoding='latin-1',ngram_range =(1,3), binary=True, stop_words='english')),('svc', LinearSVC())])\n",
    "scores = cross_val_score(svc_clf_pipe, X, y, cv=5)\n",
    "avg=sum(scores)/len(scores)\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into train and test for class prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1225, 5318)\n"
     ]
    }
   ],
   "source": [
    "ngram_count_vectorizer = CountVectorizer(encoding='latin-1',ngram_range =(1,3), binary=True, stop_words='english')\n",
    "X_train_vec2 = ngram_count_vectorizer.fit_transform(X_train)\n",
    "X_test_vec2 = ngram_count_vectorizer.transform(X_test)\n",
    "print(X_test_vec1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = LinearSVC(C=1)\n",
    "\n",
    "# use the training data to train the model\n",
    "svm_clf.fit(X_train_vec2,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 features for all the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.27118103767448165, 'implications'), (0.281271136429408, 'appropriate'), (0.28239645665549507, 'warranted'), (0.320370516940447, 'required'), (0.32501153522390197, 'need'), (0.3345731182977772, 'necessary'), (0.35255033282683756, 'research'), (0.41359608663428654, 'safety'), (0.45821902063676995, 'needed'), (0.47300240932011867, 'studies')]\n"
     ]
    }
   ],
   "source": [
    "feature_ranks01 = sorted(zip(svm_clf.coef_[0], ngram_count_vectorizer.get_feature_names()))\n",
    "no_relationship_features = feature_ranks01[-10:]\n",
    "print(no_relationship_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.2784801419768663, 'contributed'), (0.2830401830237102, 'does'), (0.29554792850273665, 'benefits'), (0.3158617837774444, 'did'), (0.3197973841858111, 'improves'), (0.3280390480421855, 'effect'), (0.38021941884597116, 'effects'), (0.42590354631187605, 'resulted'), (0.49800960155085194, 'effective'), (0.49841973633059633, 'improved')]\n"
     ]
    }
   ],
   "source": [
    "feature_ranks11 = sorted(zip(svm_clf.coef_[1], ngram_count_vectorizer.get_feature_names()))\n",
    "direct_causal_features = feature_ranks11[-10:]\n",
    "print(direct_causal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.23330942239722516, 'play role'), (0.234466007540729, 'appears'), (0.2676226172478021, 'useful'), (0.27806354736097505, 'protective'), (0.2801402147969131, 'play'), (0.32616222202520345, 'mediated bmi'), (0.32616222202520345, 'relations'), (0.32616222202520345, 'relations mediated'), (0.32616222202520345, 'relations mediated bmi'), (0.33072537426796417, 'improve')]\n"
     ]
    }
   ],
   "source": [
    "feature_ranks21 = sorted(zip(svm_clf.coef_[2], ngram_count_vectorizer.get_feature_names()))\n",
    "coditional_causal_features = feature_ranks21[-10:]\n",
    "print(coditional_causal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3214848901794152, 'variable'), (0.32382960595114096, 'associations'), (0.3429875861288185, 'increased'), (0.36042548512064326, 'higher'), (0.41992066195961864, 'predict'), (0.4976041950824333, 'predictor'), (0.5058405320508966, 'correlated'), (0.5415959560489805, 'association'), (0.5592446227604638, 'related'), (0.9350804907517982, 'associated')]\n"
     ]
    }
   ],
   "source": [
    "feature_ranks31 = sorted(zip(svm_clf.coef_[3], ngram_count_vectorizer.get_feature_names()))\n",
    "correlational_features = feature_ranks31[-10:]\n",
    "print(correlational_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[515  13   2  42]\n",
      " [ 76  73   5  35]\n",
      " [ 46   9   4  17]\n",
      " [ 70   6   1 311]]\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix (row: ground truth; col: prediction)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = svm_clf.fit(X_train_vec2, y_train).predict(X_test_vec2)\n",
    "cm=confusion_matrix(y_test, y_pred, labels=[0,1,2,3])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78846154 0.52985075 0.6        0.66342412]\n",
      "[0.78846154 0.37566138 0.03947368 0.87886598]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79       572\n",
      "           1       0.53      0.38      0.44       189\n",
      "           2       0.60      0.04      0.07        76\n",
      "           3       0.66      0.88      0.76       388\n",
      "\n",
      "    accuracy                           0.71      1225\n",
      "   macro avg       0.65      0.52      0.51      1225\n",
      "weighted avg       0.70      0.71      0.68      1225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "print(precision_score(y_test, y_pred, average=None))\n",
    "print(recall_score(y_test, y_pred, average=None))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['0','1','2','3']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Condom use  did increase over time in both groups.\"\n",
      "Patients with body mass index >40\\\\xa0kg/m2 have greater than twice the risk for complications with odds ratios increasing with increasing body mass index class.\n",
      "Dietary cholesterol intake did not have an association with LDL-C level or with risk for coronary artery calcification in apparently healthy Korean adults.\n",
      "Weight loss, satiety and adverse symptoms demonstrated only slight changes between 3 and 8\\\\xa0years post-operatively.\n",
      "Overall hypoglycemia rates were similar except for an increase in 0-2-h postmeal hypoglycemia with faster aspart.\n",
      "During the same time period, the weight gain of very preterm infants improved, significantly.\n",
      "errors: 6\n"
     ]
    }
   ],
   "source": [
    "err_cnt = 0\n",
    "for i in range(0, len(y_test)):\n",
    "    if(y_test[i]==3 and y_pred[i]==1):\n",
    "        print(X_test[i])\n",
    "        err_cnt = err_cnt+1\n",
    "print(\"errors:\", err_cnt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
