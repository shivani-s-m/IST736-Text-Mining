{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3: Multinomial Na√Øve Bayes for Fake Review Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as p\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df=p.read_csv(\"deception_data_converted_final.tsv\", delimiter='\\t')\n",
    "y1=df['sentiment'].values\n",
    "y2=df['lie']\n",
    "X=df['review'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validating using 5 runs for different vectorizers and picking the vectroizer with the highest average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8578947368421053\n",
      "0.8368421052631578\n",
      "0.8467836257309941\n"
     ]
    }
   ],
   "source": [
    "##MNB TFIDF\n",
    "mNB_tfidf_pipe = Pipeline([('nb_tf',TfidfVectorizer(encoding='latin-1',use_idf=True,binary=False, stop_words='english')),('nb',MultinomialNB())])\n",
    "scores = cross_val_score(mNB_tfidf_pipe,X,y1,cv=5)\n",
    "print(sum(scores)/len(scores))\n",
    "\n",
    "##MNB TF\n",
    "mNB_tf_pipe = Pipeline([('nb_tf',TfidfVectorizer(encoding='latin-1',use_idf=False,binary=False, stop_words='english')),('nb',MultinomialNB())])\n",
    "scores = cross_val_score(mNB_tf_pipe,X,y1,cv=5)\n",
    "print(sum(scores)/len(scores))\n",
    "\n",
    "##MNB with Bool\n",
    "nb_clf_pipe = Pipeline([('vect', CountVectorizer(encoding='latin-1', binary=True, stop_words='english')),('nb', MultinomialNB())])\n",
    "scores = cross_val_score(nb_clf_pipe, X, y1, cv=5)\n",
    "avg=sum(scores)/len(scores)\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into train and test for sentiment prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y1, test_size=0.4, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the data using the tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 931)\n"
     ]
    }
   ],
   "source": [
    "unigram_tfidf_vectorizer = TfidfVectorizer(encoding='latin-1',use_idf=True,binary=False, stop_words='english')\n",
    "X_train_vec1 = unigram_tfidf_vectorizer.fit_transform(X_train1)\n",
    "X_test_vec1 = unigram_tfidf_vectorizer.transform(X_test1)\n",
    "print(X_test_vec1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n' 'p']\n",
      "(2, 931)\n"
     ]
    }
   ],
   "source": [
    "# import the MNB module\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# initialize the MNB model\n",
    "nb_clf= MultinomialNB()\n",
    "\n",
    "# use the training data to train the MNB model\n",
    "# feature_log_prob_ stores the conditional probs for all categories\n",
    "# if the labels are strings, the index is in alphabetic order\n",
    "# e.g. 'f' comes before 't' in alphabet, so 'f' is in [0] dimension and 't' in [1]\n",
    "\n",
    "nb_clf.fit(X_train_vec1,y_train1)\n",
    "print(nb_clf.classes_)\n",
    "print(nb_clf.feature_log_prob_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 features for negative and positive reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-0.6936468428417388, 'terrible'), (-0.6820915714871552, 'asked'), (-0.6451006621473727, 'bad'), (-0.621652775316961, 'minutes'), (-0.6128970832082654, 'took'), (-0.5836211500244861, 'come'), (-0.5622665938458997, 'said'), (-0.5573960510736526, 'indian'), (-0.5412291970875955, 'did'), (-0.5311061215048722, 'came')]\n",
      "[(0.5277270244748582, 'japanese'), (0.5781783791278325, 'nice'), (0.5898845287400594, 'great'), (0.6142792786278921, 'atmosphere'), (0.629705703597617, 'friendly'), (0.632404171580343, 'noodle'), (0.6443672842543862, 'need'), (0.7344205547266469, 'fresh'), (0.8389046726461666, 'amazing'), (0.8957289492509446, 'best')]\n"
     ]
    }
   ],
   "source": [
    "log_ratios = []\n",
    "features = unigram_tfidf_vectorizer.get_feature_names()\n",
    "neg_cond_prob = nb_clf.feature_log_prob_[0]\n",
    "pos_cond_prob = nb_clf.feature_log_prob_[1]\n",
    "\n",
    "for i in range(0, len(features)):\n",
    "  log_ratio = pos_cond_prob[i] - neg_cond_prob[i]\n",
    "  log_ratios.append(log_ratio)\n",
    "\n",
    "ranks1 = sorted(zip(log_ratios, features))\n",
    "print(ranks1[:10])\n",
    "print(ranks1[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8918918918918919"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clf.score(X_test_vec1,y_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17  1]\n",
      " [ 3 16]]\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix (row: ground truth; col: prediction)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred1 = nb_clf.fit(X_train_vec1, y_train1).predict(X_test_vec1)\n",
    "cm=confusion_matrix(y_test1, y_pred1, labels=['n', 'p'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking accuracy, precision, recall, f1 score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85       0.94117647]\n",
      "[0.94444444 0.84210526]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           n       0.85      0.94      0.89        18\n",
      "           p       0.94      0.84      0.89        19\n",
      "\n",
      "    accuracy                           0.89        37\n",
      "   macro avg       0.90      0.89      0.89        37\n",
      "weighted avg       0.90      0.89      0.89        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "print(precision_score(y_test1, y_pred1, average=None))\n",
    "print(recall_score(y_test1, y_pred1, average=None))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['n', 'p']\n",
    "print(classification_report(y_test1, y_pred1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'This place was one of the best restaurant I have been. The price is little expensive, but the food and the service is best around the area. I went here with my family, and we ordered 4 dishes. They were all well cooked, and their taste were nicely balanced. Waiters came when we needed them without having to call for them. I would definitely recommend it to everyone visiting this area. '\n",
      "'Ruby Tuesday is my favorite America Style Restaurant. The salad is awesome. And I like the baby pork ribs so much . So does the coconut shrimp.'\n",
      "?\n",
      "errors: 3\n"
     ]
    }
   ],
   "source": [
    "err_cnt = 0\n",
    "for i in range(0, len(y_test1)):\n",
    "    if(y_test1[i]=='p' and y_pred1[i]=='n'):\n",
    "        print(X_test1[i])\n",
    "        err_cnt = err_cnt+1\n",
    "print(\"errors:\", err_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Carlo\\'s Plate Shack was the worst dining experience of my life. Although my Southern Comfort Plate sounded to die for, the staff was extremely unhelpful at every turn. We started off with drinks, I had a sick Loganberry milkshake, and my friends had fresh brewed, but bland, iced tea (the ice likely melted and diluted). Eventually our server returned a half hour later to take our orders. I had the aforementioned Southern Comfort Plate, while my friends ordered the Buffalo Chicken Plate and the Hawaiian Plate Lunch. The Southern Comfort Plate came out first, a good 15 minutes before the others, and was extremely greasy. The other 2 ended up being nearly room temperature when they came out. Our server failed to return again to check on us until she brought our check rather abruptly. We want to give this place a chance, but it\\'s rather difficult to subject ourselves to such brutal service and pay money.'\n",
      "errors: 1\n"
     ]
    }
   ],
   "source": [
    "err_cnt = 0\n",
    "for i in range(0, len(y_test1)):\n",
    "    if(y_test1[i]=='n' and y_pred1[i]=='p'):\n",
    "        print(X_test1[i])\n",
    "        err_cnt = err_cnt+1\n",
    "print(\"errors:\", err_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validating using 5 runs for different vectorizers and picking the vectroizer with the highest average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5871345029239766\n",
      "0.5871345029239766\n",
      "0.5865497076023393\n"
     ]
    }
   ],
   "source": [
    "##MNB TFIDF\n",
    "mNB_tfidf_pipe = Pipeline([('nb_tf',TfidfVectorizer(encoding='latin-1',use_idf=True,binary=False, stop_words='english')),('nb',MultinomialNB())])\n",
    "scores = cross_val_score(mNB_tfidf_pipe,X,y2,cv=5)\n",
    "print(sum(scores)/len(scores))\n",
    "\n",
    "##MNB TF\n",
    "mNB_tf_pipe = Pipeline([('nb_tf',TfidfVectorizer(encoding='latin-1',use_idf=False,binary=False, stop_words='english')),('nb',MultinomialNB())])\n",
    "scores = cross_val_score(mNB_tf_pipe,X,y2,cv=5)\n",
    "print(sum(scores)/len(scores))\n",
    "\n",
    "##MNB with Bool\n",
    "nb_clf_pipe = Pipeline([('vect', CountVectorizer(encoding='latin-1', binary=False, stop_words='english')),('nb', MultinomialNB())])\n",
    "scores = cross_val_score(nb_clf_pipe, X, y2, cv=5)\n",
    "avg=sum(scores)/len(scores)\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into train and test for sentiment prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y2, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the data using the tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 931)\n"
     ]
    }
   ],
   "source": [
    "unigram_tfidf_vectorizer = TfidfVectorizer(encoding='latin-1',use_idf=True,binary=False, stop_words='english')\n",
    "X_train_vec2 = unigram_tfidf_vectorizer.fit_transform(X_train2)\n",
    "X_test_vec2 = unigram_tfidf_vectorizer.transform(X_test2)\n",
    "print(X_test_vec2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f' 't']\n",
      "(2, 931)\n"
     ]
    }
   ],
   "source": [
    "# import the MNB module\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# initialize the MNB model\n",
    "nb_clf= MultinomialNB()\n",
    "\n",
    "# use the training data to train the MNB model\n",
    "# feature_log_prob_ stores the conditional probs for all categories\n",
    "# if the labels are strings, the index is in alphabetic order\n",
    "# e.g. 'f' comes before 't' in alphabet, so 'f' is in [0] dimension and 't' in [1]\n",
    "\n",
    "nb_clf.fit(X_train_vec2,y_train2)\n",
    "print(nb_clf.classes_)\n",
    "print(nb_clf.feature_log_prob_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 features for false and true reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-0.7321182906687804, 'want'), (-0.527468650204276, 'steak'), (-0.5144518712077053, 'plate'), (-0.5077382986850907, 'bring'), (-0.49123791430867936, 'free'), (-0.45086727053602704, 'price'), (-0.44610464947613604, 'casino'), (-0.43406695261205375, 'definitely'), (-0.41630393646993635, 'delicious'), (-0.4134992464866407, 'coming')]\n",
      "[(0.40733562828624414, 'people'), (0.4239142405571048, 'environment'), (0.440190693196409, 'tables'), (0.45342542076306547, 'say'), (0.4577048038840559, 'thing'), (0.4686544382951672, 'finish'), (0.49654642367645785, 'flies'), (0.5110784275619329, 'worst'), (0.5373743623980118, 'glass'), (0.5850602438996582, 'did')]\n"
     ]
    }
   ],
   "source": [
    "log_ratios = []\n",
    "features = unigram_tfidf_vectorizer.get_feature_names()\n",
    "false_cond_prob = nb_clf.feature_log_prob_[0]\n",
    "true_cond_prob = nb_clf.feature_log_prob_[1]\n",
    "\n",
    "for i in range(0, len(features)):\n",
    "  log_ratio = true_cond_prob[i] - false_cond_prob[i]\n",
    "  log_ratios.append(log_ratio)\n",
    "\n",
    "ranks2 = sorted(zip(log_ratios, features))\n",
    "print(ranks2[:10])\n",
    "print(ranks2[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5675675675675675"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clf.score(X_test_vec2,y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  2]\n",
      " [14  6]]\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix (row: ground truth; col: prediction)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred2 = nb_clf.fit(X_train_vec2, y_train2).predict(X_test_vec2)\n",
    "cm=confusion_matrix(y_test2, y_pred2, labels=['f', 't'])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking accuracy, precision, recall, f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51724138 0.75      ]\n",
      "[0.88235294 0.3       ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           f       0.52      0.88      0.65        17\n",
      "           t       0.75      0.30      0.43        20\n",
      "\n",
      "    accuracy                           0.57        37\n",
      "   macro avg       0.63      0.59      0.54        37\n",
      "weighted avg       0.64      0.57      0.53        37\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "print(precision_score(y_test2, y_pred2, average=None))\n",
    "print(recall_score(y_test2, y_pred2, average=None))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['f', 't']\n",
    "print(classification_report(y_test2, y_pred2, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'OMG. This restaurant is horrible. The receptionist did not greet us, we just stood there and waited for five minutes. The food came late and served not warm. Me and my pet ordered a bowl of salad and a cheese pizza. The salad was not fresh, the crust of a pizza was so hard like plastics. My dog didn\\'t even eat that pizza. I hate this place!!!!!!!!!!'\n",
      "'Two days ago, I went to the rooftop restaurant in NYC that served brunch. it was one of the best brunch that I have ever had. The view from the table was serene and I could see both the the Hudson River and the East River with outstanding views of Empire State Building, the Chryslers tower, Freedom tower and the Central park. A great place with great food and a perplexing view'\n",
      "errors: 2\n"
     ]
    }
   ],
   "source": [
    "err_cnt = 0\n",
    "for i in range(0, len(np.array(y_test2))):\n",
    "    if(np.array(y_test2)[i]=='f' and np.array(y_pred2)[i]=='t'):\n",
    "        print(X_test2[i])\n",
    "        err_cnt = err_cnt+1\n",
    "print(\"errors:\", err_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'This place used to be great. I can\\'t believe it\\'s current state. Instead of the cool, dimly-lit lounge that I was used to, I was in a cheap, smelly bar. The music has no soul, the bartender is mean. This place no longer exudes a welcoming spirit. The crowd is awkward and old. I want my old hangout back!!'\n",
      "'the staff at this restaurant is very unfriendly. the waitress for our table is extremely rude. we need to wait for one hour for our order to come. the place is noisy and the food isn\\'t that good.'\n",
      "'I went to this awesome restaurant in San Francisco (I forget the name), but it was on point. Huge beer list, quick seating, the menu was long but not over-whelming with great variety and unique options, and the staff was very friendly. They played great music the whole time, and the food was delicious. We ended up hanging out at the bar (the west coast has the best IPAs!) for a few hours after what was originally going to be a quick lunch, then went to a Phish show, pretty awesome day. '\n",
      "'The best restaurant I have gone to is when I went to AppleBee with my friends, the service there is so nice. Food is delicious, I liked the steak very much! The environment is very nice and clean, which makes me want to go there for more times. Also, the feeling when talking with my friends at such a good restaurant after skiing is wonderful. I want to go there again!!'\n",
      "'This diner was not at all up to par. I\\'ve been to many diners, and get eggs benedict sometimes. There was nacho cheese on my eggs, and a plateful of watery runny eggs. And it smelled like smoke. And there was no heat, in the dead of winter. Their prices are not ANYWHERE near what is reasonable. Cool mom & pop place, but terrible food, smell, and prices.'\n",
      "'Halo\\'s is home. I have been here numerous times. The staff knows my name. That\\'s the feeling I keep coming back to. The coffee is great (any time of the day, you\\'ll always get fresh coffee). They have little munchies in case you\\'re not looking to have a full meal. A great place to have a quiet afternoon by yourself and catch up on some reading, or catch up with an old friend over never-ending conversations.'\n",
      "'Pastablities is a locally owned restaurant in Syracuse. The food is simple and homey and comforting. Their famous bread is baked daily and the bakery is right next door. The bread is soft and chewy and amazing with their homemade spicy tomato sauce. The paste and cheese that I had was cream and cooked to perfection. '\n",
      "'I have been to a Asian restaurant in New York city. The menu is written by Chinese and English. When I choose a famous chinses plate called Gongbao chicken, I was surprised. The taste of it like a Thai flavor, which is cooked by curry. '\n",
      "'This cafe is located on the 2nd street from the bank. They serve fresh and good quality coffee, and they grind beans every morning. So if you needs a cup of coffee in the morning, this place is where you are looking for. The clerks are nice and passionate on what they are doing. '\n",
      "'My best restaurant is Amer Palace Hotel in my hometown. It serves delicious Indian food. I completely love their Butter Chicken and Spinach with cottage cheese. Their service is good and the food is always served hot and delicious. It is always consistent in its quality which makes it a place that I can take my friends and family, who have never been to it, without ever worrying about the experience. I love the hotel and its Indian restaurant. '\n",
      "'When you walk into TYU you may not have the highest expectations. The space is small, dark and may even be a little gloomy, but once you settle into the comfy chairs ad browse their menu - you know you\\'re in for a treat. Great food, amazing prices and definite value for money!'\n",
      "'A big piano is in the middle of the lobby and music is from is. The light is so soft that makes me feel comfortable. Seafood, which is my favorite, is so tasty that I even cannot feel that I have already full. Waitress is always smile to us and gently ask what we need.'\n",
      "'Ruby Tuesday is my favorite America Style Restaurant. The salad is awesome. And I like the baby pork ribs so much . So does the coconut shrimp.'\n",
      "?\n",
      "errors: 14\n"
     ]
    }
   ],
   "source": [
    "err_cnt = 0\n",
    "for i in range(0, len(np.array(y_test2))):\n",
    "    if(np.array(y_test2)[i]=='t' and np.array(y_pred2)[i]=='f'):\n",
    "        print(X_test2[i])\n",
    "        err_cnt = err_cnt+1\n",
    "print(\"errors:\", err_cnt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
